{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmniGlue - Feature Matching with Foundation Model Guidance\n",
    "\n",
    "This notebook will help you set up and test the OmniGlue library from Google Research, which is designed for generalizable image feature matching using foundation model guidance.\n",
    "\n",
    "OmniGlue was introduced in a CVPR 2024 paper as a solution for image matching that can better generalize to novel image domains not seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up the environment by installing the necessary packages. We'll create a conda environment, clone the repository, and install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'omniglue' already exists and is not an empty directory.\n",
      "/mnt/sagemaker-nvme/omniglue-triton/omniglue\n",
      "Obtaining file:///mnt/sagemaker-nvme/omniglue-triton/omniglue\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (3.10.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (1.26.4)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (4.11.0.86)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (11.1.0)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (2.17.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (2.4.1.post300)\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.11/site-packages (from omniglue==0.0.0) (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown->omniglue==0.0.0) (4.13.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from gdown->omniglue==0.0.0) (3.17.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.11/site-packages (from gdown->omniglue==0.0.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from gdown->omniglue==0.0.0) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib->omniglue==0.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow->omniglue==0.0.0) (3.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->omniglue==0.0.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->omniglue==0.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->omniglue==0.0.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->omniglue==0.0.0) (2024.10.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->omniglue==0.0.0) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->omniglue==0.0.0) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow->omniglue==0.0.0) (0.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown->omniglue==0.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown->omniglue==0.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown->omniglue==0.0.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown->omniglue==0.0.0) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->omniglue==0.0.0) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->omniglue==0.0.0) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow->omniglue==0.0.0) (3.1.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown->omniglue==0.0.0) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->omniglue==0.0.0) (3.0.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown->omniglue==0.0.0) (1.7.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->omniglue==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->omniglue==0.0.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow->omniglue==0.0.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->omniglue==0.0.0) (0.1.2)\n",
      "Building wheels for collected packages: omniglue\n",
      "  Building editable for omniglue (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for omniglue: filename=omniglue-0.0.0-0.editable-py3-none-any.whl size=13387 sha256=f9b6d8e322971295786d61ba08acf3b8d0c59c73933d1903ceeec5029d24bcc1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z4cf8jx2/wheels/ed/50/5f/43084c321c2a6b5983758a39681b835d591449232d87e44b8b\n",
      "Successfully built omniglue\n",
      "Installing collected packages: omniglue\n",
      "  Attempting uninstall: omniglue\n",
      "    Found existing installation: omniglue 0.0.0\n",
      "    Uninstalling omniglue-0.0.0:\n",
      "      Successfully uninstalled omniglue-0.0.0\n",
      "Successfully installed omniglue-0.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install OmniGlue and its dependencies\n",
    "!git clone https://github.com/google-research/omniglue.git\n",
    "%cd omniglue\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Required Models\n",
    "\n",
    "OmniGlue requires multiple pre-trained models to work properly:\n",
    "1. SuperPoint - For keypoint detection\n",
    "2. DINOv2 - A vision foundation model (vit-b14)\n",
    "3. OmniGlue weights - The trained OmniGlue model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sagemaker-nvme/omniglue-triton/omniglue/models\n"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "!mkdir -p models\n",
    "%cd models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SuperPoint'...\n",
      "remote: Enumerating objects: 1611, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 1611 (delta 13), reused 18 (delta 7), pack-reused 1575 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1611/1611), 549.39 MiB | 49.70 MiB/s, done.\n",
      "Resolving deltas: 100% (1078/1078), done.\n",
      "Updating files: 100% (83/83), done.\n",
      "sp_v6/\n",
      "sp_v6/saved_model.pb\n",
      "sp_v6/variables/\n",
      "sp_v6/variables/variables.index\n",
      "sp_v6/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "# Download SuperPoint\n",
    "!git clone https://github.com/rpautrat/SuperPoint.git\n",
    "!mv SuperPoint/pretrained_models/sp_v6.tgz .\n",
    "!rm -rf SuperPoint\n",
    "!tar zxvf sp_v6.tgz\n",
    "!rm sp_v6.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-25 20:20:18--  https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.24.87, 3.163.24.51, 3.163.24.93, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.24.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 346378731 (330M) [binary/octet-stream]\n",
      "Saving to: ‘dinov2_vitb14_pretrain.pth.2’\n",
      "\n",
      "dinov2_vitb14_pretr 100%[===================>] 330.33M   173MB/s    in 1.9s    \n",
      "\n",
      "2025-03-25 20:20:20 (173 MB/s) - ‘dinov2_vitb14_pretrain.pth.2’ saved [346378731/346378731]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download DINOv2 (vit-b14)\n",
    "!wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-25 20:20:21--  https://storage.googleapis.com/omniglue/og_export.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.217.123, 142.251.215.251, 172.217.14.251, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.217.123|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 45860170 (44M) [application/zip]\n",
      "Saving to: ‘og_export.zip’\n",
      "\n",
      "og_export.zip       100%[===================>]  43.74M  49.0MB/s    in 0.9s    \n",
      "\n",
      "2025-03-25 20:20:22 (49.0 MB/s) - ‘og_export.zip’ saved [45860170/45860170]\n",
      "\n",
      "Archive:  og_export.zip\n",
      "^Cplace og_export/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n"
     ]
    }
   ],
   "source": [
    "# Download OmniGlue weights\n",
    "!wget https://storage.googleapis.com/omniglue/og_export.zip\n",
    "!unzip og_export.zip\n",
    "!rm og_export.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sagemaker-nvme/omniglue-triton/omniglue\n"
     ]
    }
   ],
   "source": [
    "# Go back to the main directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries\n",
    "\n",
    "Now let's import the required libraries for testing OmniGlue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path:\n",
      "  - /opt/conda/lib/python311.zip\n",
      "  - /opt/conda/lib/python3.11\n",
      "  - /opt/conda/lib/python3.11/lib-dynload\n",
      "  - \n",
      "  - /opt/conda/lib/python3.11/site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 20:20:28.740696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 20:20:28.756642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 20:20:28.761697: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 20:20:28.773355: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported omniglue!\n"
     ]
    }
   ],
   "source": [
    "# First, let's check if we can import omniglue and debug any issues\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Print Python path to help with debugging\n",
    "print(\"Python path:\")\n",
    "for path in sys.path:\n",
    "    print(f\"  - {path}\")\n",
    "\n",
    "# Try to import omniglue with error handling\n",
    "try:\n",
    "    import omniglue\n",
    "    from omniglue import utils\n",
    "    print(\"Successfully imported omniglue!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing omniglue: {e}\")\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Make sure you're in the right directory\")\n",
    "    print(\"2. Check if the package was installed correctly\")\n",
    "    print(\"3. Try reinstalling:\")\n",
    "    print(\"   !pip install -e . --verbose\")\n",
    "    print(\"4. Check if the package is in your path:\")\n",
    "    print(\"   !pip list | grep omni\")\n",
    "    # Add the repository directory to path as a fallback\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir not in sys.path:\n",
    "        print(f\"Adding current directory to Python path: {current_dir}\")\n",
    "        sys.path.append(current_dir)\n",
    "        try:\n",
    "            import omniglue\n",
    "            from omniglue import utils\n",
    "            print(\"Successfully imported omniglue after adding current directory to path!\")\n",
    "        except ImportError as e:\n",
    "            print(f\"Still cannot import omniglue: {e}\")\n",
    "            print(\"You may need to restart the kernel after installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Test Images\n",
    "\n",
    "Let's download some sample images to test OmniGlue or use the demo images from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6364\n",
      "drwxr-xr-x  2 sagemaker-user users      85 Mar 25 18:45 .\n",
      "drwxr-xr-x 10 sagemaker-user users     309 Mar 25 19:04 ..\n",
      "-rw-r--r--  1 sagemaker-user users   85333 Mar 25 18:45 demo1.jpg\n",
      "-rw-r--r--  1 sagemaker-user users  113899 Mar 25 18:45 demo2.jpg\n",
      "-rw-r--r--  1 sagemaker-user users 1486901 Mar 25 18:45 demo_output.png\n",
      "-rw-r--r--  1 sagemaker-user users 4821703 Mar 25 18:45 og_diagram.png\n"
     ]
    }
   ],
   "source": [
    "# Check if demo images exist in the repo\n",
    "!ls -la res/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for our own test images if needed\n",
    "!mkdir -p test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define OmniGlue Matching Function\n",
    "\n",
    "Let's create a function that performs image matching using OmniGlue based on the demo script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_per_process_memory_fraction(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def match_images(image0_path, image1_path, visualize=True):\n",
    "    \"\"\"Perform OmniGlue matching between two images.\n",
    "    \n",
    "    Args:\n",
    "        image0_path: Path to the first image\n",
    "        image1_path: Path to the second image\n",
    "        visualize: Whether to visualize the matches\n",
    "        \n",
    "    Returns:\n",
    "        matches: Matched keypoints\n",
    "        visualization: Visualization of the matches if visualize=True\n",
    "    \"\"\"\n",
    "    # Load the images\n",
    "    image0 = np.array(Image.open(image0_path).convert('RGB'))\n",
    "    image1 = np.array(Image.open(image1_path).convert('RGB'))\n",
    "    \n",
    "    # Create the matcher - using the correct class name OmniGlue (not OmniGlueMatcher)\n",
    "    og = omniglue.OmniGlue(\n",
    "        og_export=\"./models/og_export\",\n",
    "        sp_export=\"./models/sp_v6\",\n",
    "        dino_export=\"./models/dinov2_vitb14_pretrain.pth\",\n",
    "    )\n",
    "    \n",
    "    # Match the images\n",
    "    start_time = time.time()\n",
    "    match_kp0, match_kp1, match_confidences = og.FindMatches(image0, image1)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Get match info\n",
    "    num_matches = match_kp0.shape[0]\n",
    "    matches = np.arange(num_matches)  # All keypoints are matched in a 1:1 correspondence\n",
    "    print(f\"Number of matches: {num_matches}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        # Create the visualization\n",
    "        visualization = utils.visualize_matches(\n",
    "            image0, image1, match_kp0, match_kp1, \n",
    "            np.eye(num_matches),  # Identity matrix for matches\n",
    "            show_keypoints=True,\n",
    "            highlight_unmatched=True,\n",
    "            title=f\"{num_matches} matches\",\n",
    "            line_width=2,\n",
    "        )\n",
    "        \n",
    "        # Display the visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"OmniGlue matches between {os.path.basename(image0_path)} and {os.path.basename(image1_path)}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return matches, visualization\n",
    "    \n",
    "    return matches, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_images_optimized(image0_path, image1_path, visualize=True, max_size=1024):\n",
    "    \"\"\"Perform OmniGlue matching between two images with memory optimization.\n",
    "    \n",
    "    Args:\n",
    "        image0_path: Path to the first image\n",
    "        image1_path: Path to the second image\n",
    "        visualize: Whether to visualize the matches\n",
    "        max_size: Maximum dimension for images (resizes if larger)\n",
    "        \n",
    "    Returns:\n",
    "        matches: Matched keypoints\n",
    "        visualization: Visualization of the matches if visualize=True\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import gc\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    import omniglue\n",
    "    from omniglue import utils\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Clear cache before starting\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Set PyTorch to use limited GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8)  # Use at most 80% of available memory\n",
    "    \n",
    "    # Load and resize images if needed\n",
    "    def load_and_resize_image(path):\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        # Resize if too large (preserving aspect ratio)\n",
    "        if max(img.size) > max_size:\n",
    "            scale = max_size / max(img.size)\n",
    "            new_size = (int(img.size[0] * scale), int(img.size[1] * scale))\n",
    "            img = img.resize(new_size, Image.LANCZIS if hasattr(Image, 'LANCZIS') else Image.LANCZOS)\n",
    "        return np.array(img)\n",
    "    \n",
    "    # Load images\n",
    "    print(\"> Loading and resizing images...\")\n",
    "    image0 = load_and_resize_image(image0_path)\n",
    "    image1 = load_and_resize_image(image1_path)\n",
    "    \n",
    "    print(f\"> Image dimensions: {image0.shape} and {image1.shape}\")\n",
    "    \n",
    "    try:\n",
    "        # Create the matcher with memory-efficient config\n",
    "        print(\"> Loading OmniGlue (and its submodules)...\")\n",
    "        start_time = time.time()\n",
    "        og = omniglue.OmniGlue(\n",
    "            og_export=\"./models/og_export\",\n",
    "            sp_export=\"./models/sp_v6\",\n",
    "            dino_export=\"./models/dinov2_vitb14_pretrain.pth\",\n",
    "        )\n",
    "        print(f\"> \\tTook {time.time() - start_time:.2f} seconds to load models.\")\n",
    "        \n",
    "        # Match the images - wrap in try/finally for cleanup\n",
    "        print(\"> Finding matches...\")\n",
    "        start_time = time.time()\n",
    "        match_kp0, match_kp1, match_confidences = og.FindMatches(image0, image1)\n",
    "        match_time = time.time() - start_time\n",
    "        \n",
    "        # Get match info\n",
    "        num_matches = match_kp0.shape[0]\n",
    "        matches = np.arange(num_matches)  # All keypoints are matched in a 1:1 correspondence\n",
    "        print(f\"> \\tFound {num_matches} matches.\")\n",
    "        print(f\"> \\tTook {match_time:.2f} seconds.\")\n",
    "        \n",
    "        # Create visualization if requested\n",
    "        if visualize:\n",
    "            print(\"> Creating visualization...\")\n",
    "            viz_start = time.time()\n",
    "            \n",
    "            # Create the visualization in a memory-efficient way (process in smaller chunks if needed)\n",
    "            visualization = utils.visualize_matches(\n",
    "                image0, image1, match_kp0, match_kp1, \n",
    "                np.eye(num_matches),  # Identity matrix for matches\n",
    "                show_keypoints=True,\n",
    "                highlight_unmatched=True,\n",
    "                title=f\"{num_matches} matches\",\n",
    "                line_width=2,\n",
    "            )\n",
    "            \n",
    "            print(f\"> \\tVisualization took {time.time() - viz_start:.2f} seconds.\")\n",
    "            \n",
    "            # Display the visualization\n",
    "            plt.figure(figsize=(12, 8))  # Reduced figure size to save memory\n",
    "            plt.imshow(visualization)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"OmniGlue: {os.path.basename(image0_path)} ↔ {os.path.basename(image1_path)}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            result = (matches, visualization)\n",
    "        else:\n",
    "            result = (matches, None)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    finally:\n",
    "        # Clean up to release memory\n",
    "        if 'og' in locals():\n",
    "            del og\n",
    "        if 'visualization' in locals():\n",
    "            del visualization\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"> Memory cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test OmniGlue with Demo Images\n",
    "\n",
    "Now let's test OmniGlue with the demo images provided in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading and resizing images...\n",
      "> Image dimensions: (667, 1000, 3) and (667, 1000, 3)\n",
      "> Loading OmniGlue (and its submodules)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742934032.081882   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.084885   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.086778   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.089174   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.090953   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.092587   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.094136   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.095802   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934032.097217   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:20:32.098646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/superpoint_extract.py:40: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.saved_model.load` instead.\n",
      "INFO:tensorflow:Restoring parameters from ./models/sp_v6/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742934046.186478   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934046.188937   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934046.190723   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934046.192510   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1742934046.194179   16893 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-03-25 20:20:46.196031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "2025-03-25 20:20:46.250670: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "/mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/dino_extract.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict_raw = torch.load(cpt_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \tTook 16.36 seconds to load models.\n",
      "> Finding matches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 20:20:47.877615: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90701\n",
      "W0000 00:00:1742934047.998469   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.065367   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.066299   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.067666   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.074011   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.075238   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.076386   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.077489   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.078693   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.081637   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.094619   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.097048   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.099363   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.106088   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.132657   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.135369   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.138328   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.142736   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.147099   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.150424   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.153506   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.158371   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.163312   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.169069   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.175200   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.181711   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.187854   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.195205   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.202104   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.213630   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.267238   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.268346   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.269433   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.270558   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.271746   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.273534   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.275046   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.276946   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.278492   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.280435   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.282526   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.284508   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.287742   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.301184   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.301907   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.302786   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.303677   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.304461   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.305255   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.306191   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.307023   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.307991   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.308925   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.310037   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.311307   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.312379   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.313349   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.314330   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.318582   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.319486   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.320664   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.321824   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.322941   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.324102   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.325436   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.326674   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.328128   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.329508   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.331109   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.333011   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.334542   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.336061   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.337610   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.342764   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.343316   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.343932   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.344555   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.345192   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.345876   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.346533   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.347306   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.348043   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.348766   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.349496   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.350188   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.350888   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.351689   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.352628   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.353422   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.359650   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.360327   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.361110   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.361887   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.362688   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.363571   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.364401   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.365328   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.366314   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.367297   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.368261   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.369231   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.370225   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.371298   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.372314   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1742934048.373459   17113 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Memory cleaned up.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 56.44 MiB is free. Process 23677 has 21.91 GiB memory in use. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 84.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test with demo images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m matches, visualization \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_images_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./res/demo1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./res/demo2.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m, in \u001b[0;36mmatch_images_optimized\u001b[0;34m(image0_path, image1_path, visualize, max_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Finding matches...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 63\u001b[0m match_kp0, match_kp1, match_confidences \u001b[38;5;241m=\u001b[39m \u001b[43mog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFindMatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m match_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Get match info\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/omniglue_extract.py:50\u001b[0m, in \u001b[0;36mOmniGlue.FindMatches\u001b[0;34m(self, image0, image1)\u001b[0m\n\u001b[1;32m     48\u001b[0m sp_features0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_extract(image0)\n\u001b[1;32m     49\u001b[0m sp_features1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp_extract(image1)\n\u001b[0;32m---> 50\u001b[0m dino_features0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdino_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m dino_features1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdino_extract(image1)\n\u001b[1;32m     52\u001b[0m dino_descriptors0 \u001b[38;5;241m=\u001b[39m dino_extract\u001b[38;5;241m.\u001b[39mget_dino_descriptors(\n\u001b[1;32m     53\u001b[0m     dino_features0,\n\u001b[1;32m     54\u001b[0m     tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(sp_features0[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     DINO_FEATURE_DIM,\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/dino_extract.py:48\u001b[0m, in \u001b[0;36mDINOExtract.__call__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/dino_extract.py:62\u001b[0m, in \u001b[0;36mDINOExtract.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     60\u001b[0m image_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_image(image)\n\u001b[1;32m     61\u001b[0m image_processed \u001b[38;5;241m=\u001b[39m image_processed\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 62\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_processed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/src/omniglue/dino_extract.py:115\u001b[0m, in \u001b[0;36mDINOExtract.extract_feature\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extracts features from image.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m  features: (B, C, H//14, W//14) torch tensor image features.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m b, _, h_origin, w_origin \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 115\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_intermediate_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_layer\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    116\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(h_origin \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_down_rate)\n\u001b[1;32m    117\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(w_origin \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_down_rate)\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino.py:315\u001b[0m, in \u001b[0;36mDinoVisionTransformer.get_intermediate_layers\u001b[0;34m(self, x, n, reshape, return_class_token, norm)\u001b[0m\n\u001b[1;32m    313\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_intermediate_layers_chunked(x, n)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_intermediate_layers_not_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[1;32m    317\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(out) \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino.py:278\u001b[0m, in \u001b[0;36mDinoVisionTransformer._get_intermediate_layers_not_chunked\u001b[0;34m(self, x, n)\u001b[0m\n\u001b[1;32m    274\u001b[0m blocks_to_take \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mrange\u001b[39m(total_block_len \u001b[38;5;241m-\u001b[39m n, total_block_len) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m n\n\u001b[1;32m    276\u001b[0m )\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m--> 278\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m blocks_to_take:\n\u001b[1;32m    280\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino_utils.py:313\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    311\u001b[0m   x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(ffn_residual_func(x))  \u001b[38;5;66;03m# FIXME: drop_path2\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m   x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[43mattn_residual_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m   x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m ffn_residual_func(x)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino_utils.py:292\u001b[0m, in \u001b[0;36mBlock.forward.<locals>.attn_residual_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mattn_residual_func\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 292\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino_utils.py:178\u001b[0m, in \u001b[0;36mMemEffAttention.forward\u001b[0;34m(self, x, attn_bias)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m XFORMERS_AVAILABLE:\n\u001b[1;32m    177\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m attn_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxFormers is required for nested tensors usage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 178\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemEffAttention do not support xFormer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/sagemaker-nvme/omniglue-triton/omniglue/third_party/dinov2/dino_utils.py:162\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m qkv \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(x)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    161\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, qkv[\u001b[38;5;241m1\u001b[39m], qkv[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 162\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    165\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 21.98 GiB of which 56.44 MiB is free. Process 23677 has 21.91 GiB memory in use. Of the allocated memory 1.29 GiB is allocated by PyTorch, and 84.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Test with demo images\n",
    "matches, visualization = match_images_optimized('./res/demo1.jpg', './res/demo2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test OmniGlue with Custom Images\n",
    "\n",
    "You can also test OmniGlue with your own images by uploading them to the `test_images` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your own images if you want to test with them\n",
    "# Then match them\n",
    "# matches, visualization = match_images('test_images/your_image1.jpg', 'test_images/your_image2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced: Test OmniGlue with Custom Parameters\n",
    "\n",
    "OmniGlue provides options to customize the matching process. Let's create a function that allows us to experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_images_custom(image0_path, image1_path, visualize=True, match_threshold=0.02):\n",
    "    \"\"\"Perform OmniGlue matching between two images with custom parameters.\n",
    "    \n",
    "    Args:\n",
    "        image0_path: Path to the first image\n",
    "        image1_path: Path to the second image\n",
    "        visualize: Whether to visualize the matches\n",
    "        match_threshold: Threshold for confident matches\n",
    "        \n",
    "    Returns:\n",
    "        matches: Matched keypoints\n",
    "        visualization: Visualization of the matches if visualize=True\n",
    "    \"\"\"\n",
    "    # Load the images\n",
    "    image0 = np.array(Image.open(image0_path).convert('RGB'))\n",
    "    image1 = np.array(Image.open(image1_path).convert('RGB'))\n",
    "    \n",
    "    # Create the matcher with custom parameters\n",
    "    og = omniglue.OmniGlue(\n",
    "        og_export=\"./models/og_export\",\n",
    "        sp_export=\"./models/sp_v6\",\n",
    "        dino_export=\"./models/dinov2_vitb14_pretrain.pth\",\n",
    "    )\n",
    "    \n",
    "    # Match the images\n",
    "    start_time = time.time()\n",
    "    match_kp0, match_kp1, match_confidences = og.FindMatches(image0, image1)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Filter matches by confidence\n",
    "    keep_idx = []\n",
    "    for i in range(match_kp0.shape[0]):\n",
    "        if match_confidences[i] > match_threshold:\n",
    "            keep_idx.append(i)\n",
    "    \n",
    "    # Apply filtering\n",
    "    filtered_kp0 = match_kp0[keep_idx]\n",
    "    filtered_kp1 = match_kp1[keep_idx]\n",
    "    filtered_confidences = match_confidences[keep_idx]\n",
    "    # Get stats\n",
    "    total_matches = match_kp0.shape[0]\n",
    "    filtered_matches = len(filtered_kp0)\n",
    "    \n",
    "    print(f\"Total matches found: {total_matches}\")\n",
    "    print(f\"Matches with confidence > {match_threshold}: {filtered_matches}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        # Create the visualization for filtered matches\n",
    "        visualization = utils.visualize_matches(\n",
    "            image0, image1, \n",
    "            filtered_kp0, filtered_kp1,\n",
    "            np.eye(filtered_matches),  # Identity matrix for matches\n",
    "            show_keypoints=True,\n",
    "            highlight_unmatched=True,\n",
    "            title=f\"{filtered_matches} filtered matches (threshold: {match_threshold})\",\n",
    "            line_width=2,\n",
    "        )\n",
    "        \n",
    "        # Display the visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"OmniGlue filtered matches (threshold: {match_threshold})\")\n",
    "        plt.show()\n",
    "        \n",
    "        return filtered_kp0, filtered_kp1, filtered_confidences, visualization\n",
    "    \n",
    "    return filtered_kp0, filtered_kp1, filtered_confidences, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with custom parameters\n",
    "filtered_kp0, filtered_kp1, filtered_confidences, visualization = match_images_custom(\n",
    "    './res/demo1.jpg', './res/demo2.jpg', match_threshold=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare OmniGlue with Traditional Methods\n",
    "\n",
    "Let's compare OmniGlue with a traditional method like SIFT to see the difference in matching quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_images_sift(image0_path, image1_path, visualize=True, max_keypoints=1024):\n",
    "    \"\"\"Perform SIFT matching between two images.\n",
    "    \n",
    "    Args:\n",
    "        image0_path: Path to the first image\n",
    "        image1_path: Path to the second image\n",
    "        visualize: Whether to visualize the matches\n",
    "        max_keypoints: Maximum number of keypoints to detect\n",
    "        \n",
    "    Returns:\n",
    "        matches: Matched keypoints\n",
    "        visualization: Visualization of the matches if visualize=True\n",
    "    \"\"\"\n",
    "    # Load the images\n",
    "    image0 = cv2.imread(image0_path)\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray0 = cv2.cvtColor(image0, cv2.COLOR_BGR2GRAY)\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create SIFT detector\n",
    "    sift = cv2.SIFT_create(nfeatures=max_keypoints)\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    start_time = time.time()\n",
    "    kp0, desc0 = sift.detectAndCompute(gray0, None)\n",
    "    kp1, desc1 = sift.detectAndCompute(gray1, None)\n",
    "    \n",
    "    # Match descriptors\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(desc0, desc1, k=2)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    print(f\"Number of keypoints in image 1: {len(kp0)}\")\n",
    "    print(f\"Number of keypoints in image 2: {len(kp1)}\")\n",
    "    print(f\"Number of matches: {len(good_matches)}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    if visualize:\n",
    "        # Create the visualization\n",
    "        visualization = cv2.drawMatches(image0, kp0, image1, kp1, good_matches, None,\n",
    "                                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        \n",
    "        # Convert BGR to RGB for display\n",
    "        visualization = cv2.cvtColor(visualization, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(visualization)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"SIFT matches between {os.path.basename(image0_path)} and {os.path.basename(image1_path)}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return good_matches, visualization\n",
    "    \n",
    "    return good_matches, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with SIFT\n",
    "sift_matches, sift_visualization = match_images_sift('./res/demo1.jpg', './res/demo2.jpg', max_keypoints=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've explored OmniGlue, a generalizable image feature matching library from Google Research that leverages foundation models to improve matching across different domains.\n",
    "\n",
    "We've:\n",
    "1. Set up the environment and installed OmniGlue\n",
    "2. Downloaded the required models\n",
    "3. Tested OmniGlue with demo images\n",
    "4. Created functions for customized matching\n",
    "5. Compared OmniGlue with traditional SIFT matching\n",
    "\n",
    "OmniGlue demonstrates how foundation models can improve traditional computer vision tasks by providing generalizable guidance for feature matching."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
